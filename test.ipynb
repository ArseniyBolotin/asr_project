{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMFICkf3J6bm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ArseniyBolotin/asr_project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nR-bTybK5RL"
      },
      "outputs": [],
      "source": [
        "!pip install -r asr_project/requirements.txt\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jPkrTcqdNsSm"
      },
      "outputs": [],
      "source": [
        "# datasphere only\n",
        "# %pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXk3AFntIqgU",
        "outputId": "a86031a1-3df8-4d60-c04d-c492c427c622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pz9M9PGxlMgrWTyamwlR0049ofpUez0O\n",
            "To: /content/best_model\n",
            "100% 284M/284M [00:01<00:00, 224MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tFvww-3TeTjJzmSXPpqHuw8nvgAYV1BR\n",
            "To: /content/best_model_config.json\n",
            "100% 3.47k/3.47k [00:00<00:00, 3.25MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1pz9M9PGxlMgrWTyamwlR0049ofpUez0O\n",
        "!gdown --id 1tFvww-3TeTjJzmSXPpqHuw8nvgAYV1BR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZbzaugznMG9a"
      },
      "outputs": [],
      "source": [
        "!mv best_model_config.json config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMTjJP2xJMbd",
        "outputId": "8941651f-b953-45e8-8d0e-9ec29f560a50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading pruned 3-gram model.\n",
            "Downloaded the 3-gram language model.\n",
            "Unzipped the 3-gram language model.\n",
            "Converted language model file to lowercase.\n",
            "Loading the LM will be faster if you build a binary file.\n",
            "Reading lowercase_3-gram.pruned.1e-7.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "DeepSpeech(\n",
            "  (conv): MaskConv(\n",
            "    (seq_module): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
            "      (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (rnns): Sequential(\n",
            "    (0): BatchRNN(\n",
            "      (rnn): LSTM(1024, 512, bidirectional=True)\n",
            "    )\n",
            "    (1): BatchRNN(\n",
            "      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (rnn): LSTM(512, 512, bidirectional=True)\n",
            "    )\n",
            "    (2): BatchRNN(\n",
            "      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (rnn): LSTM(512, 512, bidirectional=True)\n",
            "    )\n",
            "    (3): BatchRNN(\n",
            "      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (rnn): LSTM(512, 512, bidirectional=True)\n",
            "    )\n",
            "    (4): BatchRNN(\n",
            "      (batch_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (rnn): LSTM(512, 512, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=28, bias=False)\n",
            "  )\n",
            ")\n",
            "Trainable parameters: 23641888\n",
            "Loading checkpoint: best_model ...\n",
            "100% 1/1 [00:00<00:00,  1.71it/s]\n"
          ]
        }
      ],
      "source": [
        "!python asr_project/test.py  -r best_model -t asr_project/test_data -o test_result.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frmsbqN3Pk-j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
